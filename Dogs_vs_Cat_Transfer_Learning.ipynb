{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dogs vs Cat Transfer Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaurasiauttkarsh/Convolution-Neural-Network-Projects/blob/master/Dogs_vs_Cat_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlI1NzZrw4CZ",
        "colab_type": "text"
      },
      "source": [
        "Downloading the model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej1yLRv_w4Y4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "956ed637-0149-4c73-8d27-555341e29d01"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-20 16:29:33--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 2607:f8b0:400e:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "\r          /tmp/ince   0%[                    ]       0  --.-KB/s               \r         /tmp/incep   4%[                    ]   4.01M  6.99MB/s               \r        /tmp/incept  38%[======>             ]  32.01M  34.0MB/s               \r       /tmp/incepti  76%[==============>     ]  64.01M  43.8MB/s               \r/tmp/inception_v3_w 100%[===================>]  83.84M  55.2MB/s    in 1.5s    \n",
            "\n",
            "2020-03-20 16:29:35 (55.2 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzAvAE2Ww4xr",
        "colab_type": "text"
      },
      "source": [
        "Importing the requisite libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BpWgg7bw4-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "f9b11804-e0cd-49ed-a317-46b6658c046c"
      },
      "source": [
        "import os\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD_GT3l9zBhp",
        "colab_type": "text"
      },
      "source": [
        "Loading the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2435ebd2-f0ba-472a-f24e-1282538bf8b2"
      },
      "source": [
        "# Loading the Inception Pretrained model from tensorflow\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n",
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "7f1e04e3-3314-4f1d-8827-88e8d3684f70"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "83fe33db-bc8e-4228-b9fc-ae642bf3f383"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "       -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/cats_and_dogs_filtered.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Define our example directories and files\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "\n",
        "train_dir = os.path.join( base_dir, 'train')\n",
        "validation_dir = os.path.join( base_dir, 'validation')\n",
        "\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats') # Directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs') # Directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats') # Directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')# Directory with our validation dog pictures\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-20 16:39:13--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  51.0MB/s    in 1.3s    \n",
            "\n",
            "2020-03-20 16:39:15 (51.0 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ea59a1d1-de34-49f7-a0e3-f21a0732adf5"
      },
      "source": [
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 20,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "Epoch 1/20\n",
            "100/100 - 27s - loss: 0.5092 - acc: 0.7580 - val_loss: 0.2630 - val_acc: 0.9240\n",
            "Epoch 2/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.3794 - acc: 0.8335 - val_loss: 0.4070 - val_acc: 0.9110\n",
            "Epoch 3/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.3404 - acc: 0.8600 - val_loss: 0.2918 - val_acc: 0.9470\n",
            "Epoch 4/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.3305 - acc: 0.8580 - val_loss: 0.3369 - val_acc: 0.9340\n",
            "Epoch 5/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.3285 - acc: 0.8550 - val_loss: 0.3147 - val_acc: 0.9500\n",
            "Epoch 6/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.3283 - acc: 0.8615 - val_loss: 0.3488 - val_acc: 0.9470\n",
            "Epoch 7/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.3023 - acc: 0.8675 - val_loss: 0.6718 - val_acc: 0.9200\n",
            "Epoch 8/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.3030 - acc: 0.8760 - val_loss: 0.4647 - val_acc: 0.9430\n",
            "Epoch 9/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.3036 - acc: 0.8735 - val_loss: 0.2819 - val_acc: 0.9600\n",
            "Epoch 10/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2860 - acc: 0.8845 - val_loss: 0.3337 - val_acc: 0.9560\n",
            "Epoch 11/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2898 - acc: 0.8670 - val_loss: 0.3918 - val_acc: 0.9490\n",
            "Epoch 12/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2678 - acc: 0.8850 - val_loss: 0.5430 - val_acc: 0.9380\n",
            "Epoch 13/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2742 - acc: 0.8820 - val_loss: 0.3709 - val_acc: 0.9540\n",
            "Epoch 14/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2612 - acc: 0.8935 - val_loss: 0.6306 - val_acc: 0.9350\n",
            "Epoch 15/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2743 - acc: 0.8870 - val_loss: 0.5531 - val_acc: 0.9430\n",
            "Epoch 16/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2661 - acc: 0.9015 - val_loss: 0.3947 - val_acc: 0.9550\n",
            "Epoch 17/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2558 - acc: 0.8970 - val_loss: 0.4835 - val_acc: 0.9480\n",
            "Epoch 18/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2518 - acc: 0.9055 - val_loss: 0.7572 - val_acc: 0.9320\n",
            "Epoch 19/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2395 - acc: 0.9055 - val_loss: 0.4955 - val_acc: 0.9470\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2515 - acc: 0.9055 - val_loss: 0.4541 - val_acc: 0.9540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "d7446664-b3e5-4612-9da1-ec05d60d4d7d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}